# VisionBridge

VisionBridgeは、視覚障害者の日常生活をサポートするためのAI駆動型アシスタントアプリケーションです。画像認識、音声認識、自然言語処理などの最新のAI技術を活用し、ユーザーの周囲の環境を解釈し、音声フィードバックを提供します。

## 主な機能

1. リアルタイム画像分析
2. 音声コマンド認識（STT + DialogFlow）
3. テキスト読み上げ（TTS）
4. 位置情報取得+経路案内

## 使用技術

- フロントエンド: Next.js, React, TypeScript
- バックエンド: Node.js, Express
- AI/ML: Google Cloud Vertex API, Google Cloud Speech-to-Text, Google Cloud Text-to-Speech
- 自然言語処理: Vertex AI (Gemini), DialogFlow CX (Generator使用)
- 地図サービス: Google Maps API
- インフラストラクチャ: Google Cloud Platform (Cloud Run, Cloud Functions)
- CI/CD: Google Cloud Build

## 現在の実装状況

1. リアルタイム画像分析
   - カメラからのリアルタイム映像をキャプチャし、分析
   - 物体検出、テキスト認識などの機能を実装

2. 音声コマンド
   - 音声入力を受け付け、自然言語処理によりコマンドを解釈
   - 基本的なナビゲーション機能（「カメラを起動」など）を実装

3. テキスト読み上げ
   - 分析結果や重要な情報を音声でユーザーに伝達

4. 位置情報サービス
   - ユーザーの現在地を取得し、音声で通知

5. 経路案内
   - 目的地までの経路を取得し、視覚障害者向けに最適化された案内を生成

6. オフライン対応
   - 基本的なオフライン機能を実装（オフラインページの表示）

7. 多言語対応
   - i18nextを使用した多言語サポートの基盤を実装

## 今後の展望

- より高度でリアルタイムな画像・動画分析機能の追加（Pub/SubとDataflowの組み合わせなど）
- ユーザーの行動パターン学習による個別化されたサポート
- コミュニティ機能の追加（ユーザー間での情報共有など）
- より多くの言語サポートの追加

## 貢献方法

プロジェクトへの貢献に興味がある方は、新機能の提案、バグ報告、ドキュメントの改善など、あらゆる形の貢献を歓迎します。

## ライセンス

このプロジェクトはMITライセンスの下で公開されています。詳細は[LICENSE](LICENSE)ファイルをご覧ください。
